\chapter{Kết luận và hướng phát triển}
\label{Chapter5}

\section{Kết luận}

Trong khóa luận này, chúng tôi nghiên cứu về bài toán huấn luyện mạng nơ-ron nhiều tầng ẩn bằng thuật toán Adam. Cụ thể, chúng tôi tập trung tìm hiểu các khó khăn của việc huấn luyện một mạng nơ-ron nhiều tầng ẩn, cũng như cách mà các thuật toán tối ưu tiếp cận và giải quyết các khó khăn đó, với trọng tâm được đặt vào thuật toán Adam \cite{kingma2014adam}. Dưới đây là một số kết quả đạt được của khóa luận.

Chúng tôi tìm hiểu, cài đặt lại và sử dụng các thuật toán SGD, Momentum, Adagrad, RMSprop, Adam (cùng một số thuật toán khác) để kiểm tra cách hoạt động của các thuật toán này trong nhiều tình huống khác nhau, từ mô phỏng bằng dữ liệu ngẫu nhiên đến huấn luyện những kiến trúc mạng nơ-ron được sử dụng trong thực tế trên các tập dữ liệu phổ biến. Ngoài ra, chúng tôi cũng ứng dụng các phương pháp tăng tốc tính toán như véc-tơ hóa trên CPU (Central Processing Unit) bằng thư viện Numpy và tính toán song song trên GPU (Graphics Processing Unit) bằng thư viện Pytorch. Kết quả của các thuật toán do chúng tôi cài đặt có thể tái tạo được một phần kết quả được công bố trong bài báo. Ngoài ra, với kiến trúc VGG16 và tập dữ liệu ImageNet, chúng tôi sử dụng TPU (Tensor Processing Unit) trên nền tảng Google Cloud để rút ngắn thời gian thực hiện thí nghiệm.

Chúng tôi thực hiện một số thí nghiệm nhằm phân tích khả năng tối ưu của các thuật toán trong nhiều tình huống khác nhau. Chẳng hạn, chúng tôi phân tích cách mà các thuật toán di chuyển trong bề mặt rãnh hẹp, cụ thể là độ lớn của các bước cập nhật theo từng trục của rãnh. Ngoài ra, chúng tôi cũng xem xét các trường hợp tối ưu và không tối ưu của Adam. Kết quả cho thấy rằng Adam không chỉ phát huy được ưu điểm của các thuật toán cơ sở là Momentum và RMSprop về tốc độ và khả năng thích ứng tỉ lệ học, mà còn khắc phục được một số điểm yếu của các thuật toán này như sự dao động và khả năng sửa sai khi di chuyển lố qua khỏi điểm cực tiểu. Chúng tôi cũng thực hiện thí nghiệm trên các kiến trúc mạng nơ-ron nhiều tầng ẩn được sử dụng phổ biến hiện nay, và cho thấy rằng Adam thường đạt được kết quả tốt nhất.

Chúng tôi cũng phân tích một số hạn chế của thuật toán như:

\begin{itemize}
	\item Thời gian cần cho từng bước tối ưu của Adam lâu hơn các thuật toán còn lại do Adam thực hiện tính toán cả momentum lẫn thích ứng tỉ lệ học. Ngoài ra, Adam còn có thêm công đoạn bias-correction để các bước tối ưu đầu tiên không bị bias về 0. Tuy nhiên, sau khi đã thực hiện được nhiều bước cập nhật thì bước bias-correction này không còn cần thiết nữa. Vì vậy, về lâu dài, Adam vẫn tốn thời gian cho bước bias-correction nhưng lại không giúp ích cho quá trình cập nhật.
	\item Trong trường hợp rãnh hẹp có các trục không trùng với trọng số, Adam cũng gặp khó khăn như các thuật toán tỉ lệ học thích ứng khác. Các thuật toán này thực hiện thay đổi tỉ lệ học cho từng trọng số một cách riêng biệt, dẫn đến hiệu quả bị giảm sút khi rãnh hẹp có trục chéo, tức là có sự phụ thuộc giữa các trọng số với nhau.
\end{itemize}

\section{Hướng phát triển}

Placeholder